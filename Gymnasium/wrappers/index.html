
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../creating_a_new_environment/">
      
      
        <link rel="next" href="../../concepts/action_masking/">
      
      <link rel="icon" href="../../images/favicon-32x32.png">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-9.0.15">
    
    
      
        <title>Wrappers - RLO</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.113286f1.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.a0c5b2b5.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Ubuntu";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="green" data-md-color-accent="orange">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#wrappers" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="RLO" class="md-header__button md-logo" aria-label="RLO" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 19h4.6L2.62 8.64C2.23 8 2 7.29 2 6.5a3.999 3.999 0 0 1 7.87-1H14V3c0-1.1.9-2 2-2v2.59L17.59 2H22v2h-3.59L16 6.41v.18L18.41 9H22v2h-4.41L16 9.41V12a2 2 0 0 1-2-2V7.5H9.87c-.1.39-.26.76-.46 1.1l6 10.4H20a2 2 0 0 1 2 2v1H2v-1c0-1.1.9-2 2-2m3.91-9c-.56.32-1.21.5-1.91.5l4.91 8.5h2.19l-5.19-9M6 4.5a2 2 0 0 0-2 2c0 1.11.89 2 2 2 1.11 0 2-.89 2-2a2 2 0 0 0-2-2Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            RLO
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Wrappers
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="RLO" class="md-nav__button md-logo" aria-label="RLO" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 19h4.6L2.62 8.64C2.23 8 2 7.29 2 6.5a3.999 3.999 0 0 1 7.87-1H14V3c0-1.1.9-2 2-2v2.59L17.59 2H22v2h-3.59L16 6.41v.18L18.41 9H22v2h-4.41L16 9.41V12a2 2 0 0 1-2-2V7.5H9.87c-.1.39-.26.76-.46 1.1l6 10.4H20a2 2 0 0 1 2 2v1H2v-1c0-1.1.9-2 2-2m3.91-9c-.56.32-1.21.5-1.91.5l4.91 8.5h2.19l-5.19-9M6 4.5a2 2 0 0 0-2 2c0 1.11.89 2 2 2 1.11 0 2-.89 2-2a2 2 0 0 0-2-2Z"/></svg>

    </a>
    RLO
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        Reinforcement Learning Observations
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../reinforcement_learning/" class="md-nav__link">
        Reinforcement Learning
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
      
      
      
        <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
          Gymnasium
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Gymnasium
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../gym/" class="md-nav__link">
        Gym / Gymnasium
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../spaces/" class="md-nav__link">
        Spaces
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../creating_a_new_environment/" class="md-nav__link">
        Creating a new Gymnasium environment
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Wrappers
      </a>
      
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
      
      
      
        <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
          concepts
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          concepts
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../concepts/action_masking/" class="md-nav__link">
        Action Masking
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="wrappers">Wrappers</h1>
<p>A wrapper in Gym / Gymnasium is just an environment that delegates its calls to another environment, potentially doing first some adjustments. Why is it a good idea and when will we be using wrappers?</p>
<p>The agents developed against Gym environments in mind, expect a specific interface. That is in particular the 'step' function. One is expected to pass as an argument to the 'step' function an action from the <strong>action space</strong> and one expects to receive in return an observation (the next observation) from the <strong>observation space</strong>. The <strong>reward</strong> that is returned from the 'step' function determines also if the agent is able to learn the desired behaviour, and is not less important from the observation and the learning algorithm itself.</p>
<p>What do you do when you want your agent to think of the problem a little different. What do you do if you want the action space to be a bit different? I'll give an example. The environment expects a target destination on an '8x8' board game. You train an agent with your preferred RL library, and a suitable method, yet the agent seems to learn very slow. Let's assume that the agent avoids illegal moves, for example, by taking into account <a href="../../concepts/action_masking">action masking</a>.</p>
<p>Still the "learning" is slow. You brainstorm with friends and they point that your (agent) piece can only move {up, left, down, right}. You hypnotise that if the action space is changed to those four possible actions, the agent will learn faster. To try you quickly wrap the original environment, with an environment that declares its ‘action_space’ with above four directions, and translates this action into the target square. That's it. You can train an agent with the "new" environment and see if the learning is faster.</p>
<p>While you can create a new environment to wrap the old environment, or also to create a new general wrapper based on <em>gym.Wrapper</em>, in above case you can actually base your wrapper on <em>gym.ActionWrapper</em>. If you base your wrapper on <em>gym.ActionWrapper</em>, you only need to have the new <em>action_space</em> available and to implement a function called <em>action</em> that takes an action from the new action space (the one of the wrapper), and return the matching action of the wrapped environment. For example, something I did in <a href="https://github.com/zbenmo/qwertyenv">qwertyenv</a>.</p>
<pre><code class="language-py">import gym
from typing import Tuple, Callable
import numpy as np


class UpDownLeftRight(gym.ActionWrapper):
  &quot;&quot;&quot;
  A gym environment wrapper to enable U/D/L/R action space when the wrapped environment
  actually expects a destination in cartesian coordinates.
  &quot;&quot;&quot;

  def __init__(self, env: gym.Env,
               get_current_location: Callable[[], Tuple[int, int]]):

    super().__init__(env)
    self.get_current_location = get_current_location

    self.action_space = gym.spaces.Discrete(4)

    self.udlr_action_to_board_action = {
      0: (0, -1), # up
      1: (0, +1), # down
      2: (-1, 0), # left
      3: (+1, 0), # right
    }

  def action(self, action: int) -&gt; Tuple[int, int]:
    current_location = self.get_current_location()
    return tuple(np.add(current_location, self.udlr_action_to_board_action[action]))
</code></pre>
<p>Note, that you are very welcome to wrap your wrapped environment yet another time, and as many times are you need. A wrapped environment is still just an environment.</p>
<p>There are (at least) two additional useful wrapper base classes. The one is <em>ObservationWrapper</em>.</p>
<p>For example, you may wish to convert an RGB image into a monocolour image, as you believe it is simpler to learn from monocolour image. You can also build a <em>ObservationWrapper</em> to enrich the observation by introducing a short history to capture motion. Think of a single frame from an ATARI game, say a ball is heading towards you. Can you tell if it is going to the left or to the right? If you are given a few additional frames from the past you may see the direction.</p>
<p>Wait, aren't we breaking the Markov Decision Process (<strong>MDP</strong>) assumption? And what is the <strong>MDP</strong> assumption to begin with?</p>
<p>In order to simplify the world a little, we assume that at any given moment the state of the environment represents everything that we need to know in order to act. What happened before with the environment, our (the agent's) past mistakes, nothing matters.</p>
<p>Wanted to use here "carpe diem", yet the expression is not appropriate as the future actually is very relevant. You do what is right now, yet of course you need to take into account the future and try to foresee it and what will be the consequences of your current action. Regrets are not helpful, but planning of some sort is the essence of RL.
The environment, if indeed an <strong>MDP</strong>, behaves similarly, subject to randomness, when we return to the same state and take the same action. This is exactly what an agent needs to learn.</p>
<p>So, back to the question, did we break the <strong>MDP</strong> assumption by introducing history? By changing the observation space, we've created a new <strong>MDP</strong>, for which there are more states. So still an <strong>MDP</strong> but a more detailed one. A thing that can help or harm the learning process. Yet to experiment.</p>
<p>The other useful wrapper base class is <em>RewardWrapper</em>. Why to touch the reward? Maybe a reward of <em>+1</em> / <em>-1</em> at the end of the game is correct, but it takes the agent a lot of time to get to a win, and on the way getting no signal for progress is not helpful. We can add indication of good progress by giving some small rewards signals on the way. This will be under <strong>reward shaping</strong>. A very important concept. Another reason that we may want to change the reward is in order to scale / normalize it for the benefit of our neural network learning optimization.</p>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.208ed371.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.2a6f1dda.min.js"></script>
      
    
  </body>
</html>