
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="..">
      
      
        <link rel="next" href="../Gymnasium/gym/">
      
      <link rel="icon" href="../images/favicon-32x32.png">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-9.0.15">
    
    
      
        <title>Reinforcement Learning - RLO</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.113286f1.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.a0c5b2b5.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Ubuntu";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="green" data-md-color-accent="orange">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#reinforcement-learning" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="RLO" class="md-header__button md-logo" aria-label="RLO" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 19h4.6L2.62 8.64C2.23 8 2 7.29 2 6.5a3.999 3.999 0 0 1 7.87-1H14V3c0-1.1.9-2 2-2v2.59L17.59 2H22v2h-3.59L16 6.41v.18L18.41 9H22v2h-4.41L16 9.41V12a2 2 0 0 1-2-2V7.5H9.87c-.1.39-.26.76-.46 1.1l6 10.4H20a2 2 0 0 1 2 2v1H2v-1c0-1.1.9-2 2-2m3.91-9c-.56.32-1.21.5-1.91.5l4.91 8.5h2.19l-5.19-9M6 4.5a2 2 0 0 0-2 2c0 1.11.89 2 2 2 1.11 0 2-.89 2-2a2 2 0 0 0-2-2Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            RLO
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Reinforcement Learning
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="RLO" class="md-nav__button md-logo" aria-label="RLO" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 19h4.6L2.62 8.64C2.23 8 2 7.29 2 6.5a3.999 3.999 0 0 1 7.87-1H14V3c0-1.1.9-2 2-2v2.59L17.59 2H22v2h-3.59L16 6.41v.18L18.41 9H22v2h-4.41L16 9.41V12a2 2 0 0 1-2-2V7.5H9.87c-.1.39-.26.76-.46 1.1l6 10.4H20a2 2 0 0 1 2 2v1H2v-1c0-1.1.9-2 2-2m3.91-9c-.56.32-1.21.5-1.91.5l4.91 8.5h2.19l-5.19-9M6 4.5a2 2 0 0 0-2 2c0 1.11.89 2 2 2 1.11 0 2-.89 2-2a2 2 0 0 0-2-2Z"/></svg>

    </a>
    RLO
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        Reinforcement Learning Observations
      </a>
    </li>
  

    
      
      
      

  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Reinforcement Learning
      </a>
      
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
      
      
      
        <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
          Gymnasium
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          Gymnasium
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Gymnasium/gym/" class="md-nav__link">
        Gym/Gymnasium
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Gymnasium/spaces/" class="md-nav__link">
        Spaces
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Gymnasium/creating_a_new_environment/" class="md-nav__link">
        Creating a new Gymnasium environment
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../Gymnasium/wrappers/" class="md-nav__link">
        Wrappers
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
      
      
      
        <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
          PettingZoo
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          PettingZoo
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../PettingZoo/pettingzoo/" class="md-nav__link">
        PettingZoo
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../PettingZoo/wrapping_pz_into_gym/" class="md-nav__link">
        Wrapping a PettingZoo into a Gymnasium one
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
      
      
      
        <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
          concepts
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          concepts
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../concepts/action_masking/" class="md-nav__link">
        Action Masking
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


<h1 id="reinforcement-learning">Reinforcement Learning</h1>
<p>We want to build software that automates tasks or acts on our behalf in various situations.
This is nothing new. We have build software for some time now. We have came up with algorithms and engineering solutions.</p>
<p>The future lies apparently with <strong>machine learning</strong>. We can build parts of our software systems in new ways; by <strong>training</strong> software from examples.
So instead of figuring how to do stuff, we communicate to the software what we want, and the software is built automatically from this "description".</p>
<p>To teach software to distinguish between cats and dogs in images, we provide examples of cats and examples of dogs and we use <strong>supervised learning</strong>. Supervised learning is a machine learning technique in which a <strong>model</strong> picks up statistical hints from labeled examples, desirably till it can fulfil the task of predicting correctly the labels on unseen examples. Hence we have achieved a software solution that can carry on from now, in telling dogs from cats (and humans can enjoy and supervise, while the machines do the hard work).</p>
<p>Reinforcement learning is a similar concept. We want software that can play Chess against us, or <strong>control</strong> a self-driving car, and more. Note that here there are multiple steps. Not just a single decision; cat or dog, but rather a series of <strong>actions</strong>. The software “wins” only if all its moves led to a victory. The car needs to get safely to the destination, following the traffic rules and in a reasonable time. Accelerating, slowing, changing the wheel orientation, all need to contribute for this complex task.</p>
<p>To some degree we can employ again supervised learning. In each situation (state), we can label the desired action, for example by recording the actions of a human driver. We can then train a model to <strong>imitate</strong> the human by taking similar actions in similar situations. There are many recorded Chess games to learn from, we can try to train a model based on those games.
Can we do even better than our role model? Can we watch someone else, learn both from their successes and also from their mistakes? Can we combine the tricks that we learn from multiple teachers? Can we try ourselves and gain some additional experience?</p>
<p>Reinforcement learning is a complementary technique to train models or here we’ll call those <strong>agents</strong>. Reinforcement learning may be more suitable for those control settings. For example with Chess, a move is actually a part of a plan. Learning to repeat a move without gasping what needs to be done later may not work without extensive training set that may not be available, or is too hard to achieve with supervised training. The approach with reinforcement learning is to let the agent learn from interacting with the <strong>environment</strong>.</p>
<p>The environment produces <strong>observations</strong> and the actions of the agent are communicated to the environment. The state of the environment changes and the agent needs to learn to make smart decisions about its actions. The agent learns this time not from labels but rather by a <strong>reward mechanism</strong> that we provide to map a transition from one <strong>state</strong><sup id="fnref:1"><a class="footnote-ref" href="#fn:1">1</a></sup> in the environment to another state and its consequences.</p>
<p>I'm bringing below an image taken from Wikipedia. In this image, we see yet another component in the setting. This is the <strong>interpreter</strong>.</p>
<figure>
  <img src="../images/Reinforcement_learning_diagram.svg.png" title="Reinforcement learning diagram"/>
  <figcaption>Reinforecement Learning Conceptual Model - Wikipedia</figcaption>
</figure>

<p>The interpreter is included in the conceptual model as we can argue that the environment is ignorant to the agent's needs and what rewards the agent. The agent may actually observe only a partial or a distorted view of the current environment's state. One may suggest that the interpreter is part of the agent, say its eyes and inner feelings.
In practice the interpreter is usually included in the environment and hence the environment can be considered as the agent's private view of the world; what happens to the agent while the agent is operating in what the agent believes to be its world.
In a Chess game, one can imagine that there are two environments. One environment for one player and anoter environment for the other player, where the two environments are being synchronized somehow behind the scenes.<br />
The environment can be shared among multiple agents in a setting where they need to compete and/or coordinate. The reward may be unique for each of the agents, or shared. The same goes for the observation.</p>
<p>The agent should learn a <strong>policy</strong> to map an observation to the best action as to be rewarded as much as possible during the <strong>episode</strong>. In other words, the agent shall attempt to maximize the cumulative reward to some time horizon. For example the agent shall try to learn to win the Chess game, or to bring the passengers safely to their destination, while avoiding fines and in a reasonable time. There is much to talk about reward and how to design the reward mechanism. If in supervised learning one needs to make sure the labels are correct, here with reinforcement learning, the reward mechanism is the equivalent.</p>
<p>Note that the environment replaces the training set. By interacting with the environment, the agent can receive infinite feedback. There are some challenges however. We don’t want a car to self-drive in the real world before it is ready. We should have some simulator. The simulator should be very close to the real world and should reflect what happens in the real world. The reward mechanism, that is often also associated with the environment, should be relevant to learning the desired <strong>behavior</strong> for the agent.</p>
<p>Another very important observation here is that the experience that the agent collects depends on the agent's actions. If a robot keeps going to the left, it will never find out what is there on the right. While in supervised learning we expect the samples in the training set to be of the same distribution (identically independently distributed), the interaction of an agent with an environment are very much dependent on the agent's actions and hence cannot be assumed to be of the same distribution.</p>
<div class="footnote">
<hr />
<ol>
<li id="fn:1">
<p>A state may mean the same thing as an observation. In many settings the observation is a (partial) derivative of the state, in the sense that the environment's state is more complete and more accurate than the observation that is available to the agent.&#160;<a class="footnote-backref" href="#fnref:1" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
</ol>
</div>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "..", "features": [], "search": "../assets/javascripts/workers/search.208ed371.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../assets/javascripts/bundle.2a6f1dda.min.js"></script>
      
    
  </body>
</html>